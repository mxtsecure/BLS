{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9218, 14) (9218, 1) (6146, 14) (6146, 1)\n",
      "0.85474\n",
      "(9218, 15)\n",
      "adding 1, number of mapping nodes 154, number of enhence nodes 28, accuracy 0.85507\n",
      "(9218, 15)\n",
      "adding 2, number of mapping nodes 168, number of enhence nodes 42, accuracy 0.85105\n",
      "(9218, 15)\n",
      "adding 3, number of mapping nodes 182, number of enhence nodes 56, accuracy 0.84172\n",
      "(9218, 15)\n",
      "adding 4, number of mapping nodes 196, number of enhence nodes 70, accuracy 0.84324\n",
      "(9218, 15)\n",
      "adding 5, number of mapping nodes 210, number of enhence nodes 84, accuracy 0.8427\n",
      "RMSE: [[1.91444134]]\n",
      "MAPE: [[0.09586031]]\n",
      "R2: 0.882266491697245\n",
      "RMSE: [[1.8831905]]\n",
      "MAPE: [[0.09338683]]\n",
      "R2: 0.8850670260908508\n",
      "(matrix([[1.88170841]]), matrix([[0.09327755]]), 0.8852478615333751)\n",
      "(matrix([[1.8812346]]), matrix([[0.09329863]]), 0.8853056431498008)\n",
      "(matrix([[1.88041173]]), matrix([[0.09323882]]), 0.8854059579638911)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from numpy import random\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.io as scio\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "'''\n",
    "本文将权值矩阵和偏置合并计算,增强层采用简便的生成方式\n",
    "'''\n",
    "\n",
    "\n",
    "def show_accuracy(predictLabel,Label):\n",
    "    RMSE = np.sqrt((predictLabel-Label).T*(predictLabel-Label)/Label.shape[0]);\n",
    "    MAPE = sum(abs(predictLabel-Label))/Label.mean()/Label.shape[0]\n",
    "    R2 = r2_score(Label,predictLabel)\n",
    "    return RMSE, MAPE, R2\n",
    "\n",
    "class dataProcess:\n",
    "    def __init__(self):\n",
    "        self._mean = 0\n",
    "        self._std = 0\n",
    "        \n",
    "    def pinv(self,A,reg):\n",
    "        return np.mat(reg*np.eye(A.shape[1])+A.T.dot(A)).I.dot(A.T)\n",
    "\n",
    "\n",
    "    '''\n",
    "    参数压缩，将接近于0的参数压缩为0，减少特征\n",
    "    '''\n",
    "    def shrinkage(self,a,b):\n",
    "        z = np.maximum(a - b, 0) - np.maximum( -a - b, 0)\n",
    "        return z\n",
    "    '''\n",
    "    参数稀疏化：\n",
    "        lasso方法来解决稀疏表示过程中的优化问题\n",
    "    '''\n",
    "    def sparse_bls(self,A,b):\n",
    "        lam = 0.001   ########################此处可优化\n",
    "        itrs = 50\n",
    "        AA = np.dot(A.T,A)   \n",
    "        m = A.shape[1]\n",
    "        n = b.shape[1]\n",
    "        wk = np.zeros([m,n],dtype = 'double')\n",
    "        ok = np.zeros([m,n],dtype = 'double')\n",
    "        uk = np.zeros([m,n],dtype = 'double')\n",
    "\n",
    "        #特征提取层，利用L1正则化和L2正则化实现特征稀疏化\n",
    "        L1 = np.mat(AA + np.eye(m)).I\n",
    "        L2 = np.dot(np.dot(L1,A.T),b)\n",
    "        for i in range(itrs):\n",
    "            tempc = ok - uk\n",
    "            ck =  L2 + np.dot(L1,tempc)\n",
    "            ok = self.shrinkage(ck + uk, lam)\n",
    "            uk += ck - ok\n",
    "            wk = ok\n",
    "\n",
    "        return wk\n",
    "        \n",
    "\n",
    "class node_generator:\n",
    "    def __init__(self,whiten = False,NumWin=1):\n",
    "        self.Wlist = []  #存储权值和偏置\n",
    "        self.nonlinear = 0\n",
    "        self.whiten = whiten\n",
    "        self.distOfMaxAndMin = np.zeros(NumWin)    #记录每个窗口的最大值和最小值之差\n",
    "        self.meanOfEachWindow = np.zeros(NumWin)   #记录每个窗口的平均值\n",
    "\n",
    "        \n",
    "    #四个激活函数，供增强层使用\n",
    "    def sigmoid(self,data):\n",
    "        return 1.0/(1+np.exp(-data))\n",
    "    \n",
    "    def linear(self,data):\n",
    "        return data\n",
    "    \n",
    "    def tanh(self,data):\n",
    "        return (np.exp(data)-np.exp(-data))/(np.exp(data)+np.exp(-data))\n",
    "    \n",
    "    def relu(self,data):\n",
    "        return np.maximum(data,0)\n",
    "    \n",
    "    #回归中的激活函数\n",
    "    def tansig(self,x):\n",
    "        return (2/(1+np.exp(-2*x)))-1\n",
    "    def orth(self,W):\n",
    "        for i in range(0,W.shape[1]):\n",
    "            w = np.mat(W[:,i].copy()).T\n",
    "            w_sum = 0\n",
    "            for j in range(i):\n",
    "                wj = np.mat(W[:,j].copy()).T\n",
    "                w_sum += (w.T.dot(wj))[0,0]*wj \n",
    "            w -= w_sum\n",
    "            w = w/np.sqrt(w.T.dot(w))\n",
    "            W[:,i] = np.ravel(w)\n",
    "        return W\n",
    "    #生成权值矩阵\n",
    "    def generator(self,shape,times):\n",
    "        u = 0\n",
    "        for i in range(times):\n",
    "            random.seed(i+u)\n",
    "            W = 2*random.random(size=shape)-1\n",
    "            if self.whiten == True:\n",
    "                W = self.orth(W)\n",
    "            yield (W)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #第一次生成映射层节点\n",
    "    def generator_Mapping_nodes(self, X, NumWin, NumFea):\n",
    "        self.Wlist = [elem for elem in self.generator((X.shape[1],NumFea),NumWin)]\n",
    "        \n",
    "        y = np.zeros([X.shape[0],NumWin*NumFea])   #留着后面存储映射层所有窗口的特征节点\n",
    "        \n",
    "        for i in range(NumWin):\n",
    "            WeightFea = self.Wlist[i]\n",
    "            Z = X.dot(WeightFea)   #初步生成映射层节点\n",
    "            scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1)).fit(Z)   #将映射层的节点的数据归一化\n",
    "            Z = scaler.transform(Z)\n",
    "            dataprocess = dataProcess()\n",
    "            WeightFeaSparse  = dataprocess.sparse_bls(Z,X).T   #最优化权值矩阵：先通过对找到一个稀疏矩阵 W ，使H1 X W = A1\n",
    "            self.Wlist[i] = WeightFeaSparse\n",
    "            #print(WeightFeaSparse)\n",
    "            Z = X.dot(WeightFeaSparse)\n",
    "            #print(Z)\n",
    "            #将T1归一化，Min_Max归一化方法\n",
    "            self.meanOfEachWindow[i] = Z.mean()\n",
    "            self.distOfMaxAndMin[i] = Z.max() - Z.min()\n",
    "            Z = (Z - self.meanOfEachWindow[i])/self.distOfMaxAndMin[i] \n",
    "            #该操作相当于合并所有窗口\n",
    "            y[:,NumFea*i:NumFea*(i+1)] = Z\n",
    "        return y\n",
    "    \n",
    "    def generator_Enhence_nodes(self, data, NumEnhence):\n",
    "        self.Wlist = [elem for elem in self.generator((data.shape[1],NumEnhence),1)]\n",
    "        WeightEnhence = self.Wlist[0]\n",
    "        #print(WeightEnhence.shape)\n",
    "        H = data.dot(WeightEnhence)\n",
    "        \n",
    "        H = self.tansig(H)\n",
    "        \n",
    "        return H\n",
    "    \n",
    "    def transform_Map(self, testdata, NumWin, NumFea):\n",
    "        y = np.zeros([testdata.shape[0],NumWin*NumFea])   #留着后面存储映射层所有窗口的特征节点\n",
    "        for i in range(NumWin):\n",
    "            WeightFea = self.Wlist[i]\n",
    "            Z = testdata.dot(WeightFea)   #初步生成映射层节点\n",
    "            #将T1归一化，Min_Max归一化方法\n",
    "            Z = (Z - self.meanOfEachWindow[i])/self.distOfMaxAndMin[i] \n",
    "            \n",
    "            #该操作相当于合并所有窗口\n",
    "            y[:,NumFea*i:NumFea*(i+1)] = Z   \n",
    "        return y\n",
    "    \n",
    "    def transform_Enh(self, testdata):\n",
    "        WeightEnhence = self.Wlist[0]\n",
    "        H = testdata.dot(WeightEnhence)\n",
    "        \n",
    "        H = self.tansig(H)\n",
    "        \n",
    "        return H\n",
    "\n",
    "            \n",
    "        \n",
    "\n",
    "class broadnet:\n",
    "    def __init__(self, \n",
    "                 NumWin = 10,   #映射层窗口个数\n",
    "                 NumEnhence = 10,   #增强层节点个数\n",
    "                 traintimes = 100,   #训练次数\n",
    "                 map_function = 'linear',\n",
    "                 enhence_function = 'linear',\n",
    "                 NumFea = 'auto',    #映射层窗口中特征节点个数\n",
    "                 acc = 1,\n",
    "                 mapstep = 1,\n",
    "                 enhencestep = 1,\n",
    "                 reg = 2**-30):\n",
    "        \n",
    "        self._NumWin = NumWin\n",
    "        self._NumEnhence = NumEnhence\n",
    "        self._NumFea = NumFea\n",
    "        self._traintimes = traintimes\n",
    "        self._acc = acc\n",
    "        self._mapstep = mapstep\n",
    "        self._enhencestep = enhencestep\n",
    "        self._reg = reg\n",
    "        self._map_function = map_function\n",
    "        self._enhence_function = enhence_function\n",
    "                \n",
    "        self.mapping_generator = node_generator(whiten=False, NumWin=self._NumWin)   #生成映射层节点用，里面分两个函数，generator_Mapping_nodes()用于第一次生成，要初始化权值矩阵和偏置，transform_Mapping()函数用于以后生成，直接使用初始化好的权值矩阵和偏置\n",
    "        self.enhence_generator = node_generator(whiten = True)\n",
    "        self.W = 0  #输出层权值矩阵\n",
    "        self.pesuedoinverse = 0  #伪逆\n",
    "        self.local_mapgeneratorlist = []\n",
    "        self.local_enhgeneratorlist = []\n",
    "        \n",
    "    def fit(self, oridata, orilabel):\n",
    "        if self._NumFea == 'auto':  #如果没有设置每个窗口的特征节点数目，则默认为训练数据的列\n",
    "            self._NumFea = oridata.shape[1]\n",
    "        #对训练数据增量化处理\n",
    "        X = np.hstack([oridata, 0.1 * np.ones([oridata.shape[0],1])])\n",
    "        mappingdata = self.mapping_generator.generator_Mapping_nodes(X, self._NumWin, self._NumFea)\n",
    "       # print(mappingdata)\n",
    "        #对映射层输出增量化处理\n",
    "        mappingdata = np.hstack([mappingdata, 0.1 * np.ones([mappingdata.shape[0],1])])  \n",
    "        enhencedata = self.enhence_generator.generator_Enhence_nodes(mappingdata, self._NumEnhence)\n",
    "        #print(enhencedata)\n",
    "        inputdata = np.hstack([mappingdata,enhencedata])\n",
    "        \n",
    "        dataprocess = dataProcess()\n",
    "        #获取伪逆和输出层权值矩阵\n",
    "        self.pesuedoinverse = dataprocess.pinv(inputdata,self._reg)\n",
    "        self.W =  self.pesuedoinverse.dot(orilabel)\n",
    "        #print(self.W)\n",
    "        Y = inputdata.dot(self.W)\n",
    "        accuracy, i = self.accuracy(Y,orilabel),0\n",
    "        print(accuracy)\n",
    "        while i < self._traintimes and accuracy < self._acc:\n",
    "            Y = self.adding_predict(oridata, orilabel, self._mapstep, self._enhencestep, self._NumFea)  \n",
    "            accuracy = self.accuracy(Y,orilabel)\n",
    "            i += 1\n",
    "            print(\"adding {3}, number of mapping nodes {0}, number of enhence nodes {1}, accuracy {2}\".format((len(self.mapping_generator.Wlist)+len(self.local_mapgeneratorlist)*len(self.local_mapgeneratorlist[0].Wlist))*self._NumFea,(len(self.enhence_generator.Wlist)+len(self.local_enhgeneratorlist)*len(self.local_enhgeneratorlist[0].Wlist))*self._NumFea,round(accuracy,5),i))\n",
    "\n",
    "        \n",
    "    def accuracy(self, predictlabel, orilabel):\n",
    "        count = 0\n",
    "        orilabel = np.ravel(orilabel).tolist()\n",
    "        predictlabel = np.ravel(predictlabel).tolist()\n",
    "        \n",
    "        for i in range(len(orilabel)):\n",
    "            #print(math.fabs(orilabel[i] - predictlabel[i])/orilabel[i])\n",
    "            if math.fabs(orilabel[i] - predictlabel[i])/orilabel[i] < 0.2:\n",
    "                count += 1\n",
    "        return (round(count/len(orilabel),5))\n",
    "    \n",
    "    def transform(self, testdata):\n",
    "        mappingdata = self.mapping_generator.transform_Map(testdata, self._NumWin, self._NumFea)\n",
    "        mappingdata = np.hstack([mappingdata, 0.1 * np.ones([mappingdata.shape[0],1])])  \n",
    "        #print(mappingdata.shape)\n",
    "        enhencedata = self.enhence_generator.transform_Enh(mappingdata)\n",
    "        inputdata = np.hstack([mappingdata,enhencedata])\n",
    "        \n",
    "        for elem1,elem2 in zip(self.local_mapgeneratorlist,self.local_enhgeneratorlist):\n",
    "            inputdata  = np.column_stack((inputdata, elem1.transform_Map(testdata,self._mapstep,self._NumFea)))\n",
    "            inputdata  = np.column_stack((inputdata, elem2.transform_Enh(mappingdata)))\n",
    "\n",
    "        return inputdata\n",
    "    def predict(self, testdata):\n",
    "        testdata = np.hstack([testdata, 0.1 * np.ones([testdata.shape[0],1])])\n",
    "        test_inputdata = self.transform(testdata)   \n",
    "        #print(self.W)\n",
    "        return test_inputdata.dot(self.W)  \n",
    "    \n",
    "    \n",
    "    def adding_nodes(self, data, label, mapstep = 1, enhencestep = 1, batchsize = 'auto'):\n",
    "        if batchsize == 'auto':\n",
    "            batchsize = data.shape[1]\n",
    "        \n",
    "        #获取原始数据的映射层输出\n",
    "        mappingdata = self.mapping_generator.transform_Map(data,self._NumWin, self._NumFea)  \n",
    "        #print(mappingdata.shape)\n",
    "        inputdata = self.transform(data)  #获取原始数据的输出层输入\n",
    "        \n",
    "        localmap_generator = node_generator(whiten = False,NumWin=mapstep)\n",
    "        extramap_nodes = localmap_generator.generator_Mapping_nodes(data,mapstep,batchsize)  #映射层新生成的节点\n",
    "        #对映射层输出增量化处理\n",
    "        extramap_nodes = np.hstack([extramap_nodes, 0.1 * np.ones([mappingdata.shape[0],1])])  \n",
    "        print(extramap_nodes.shape)\n",
    "        localenhence_generator = node_generator(whiten = True,NumWin=0)\n",
    "        mappingdata = np.hstack([mappingdata, 0.1 * np.ones([mappingdata.shape[0],1])])\n",
    "        extraenh_nodes = localenhence_generator.generator_Enhence_nodes(mappingdata,enhencestep) #增强层新生成的节点\n",
    "        extra_nodes = np.column_stack((extramap_nodes[:,:-1],extraenh_nodes))\n",
    "        mappingdata = mappingdata[:,:-1]\n",
    "        \n",
    "        D = self.pesuedoinverse.dot(extra_nodes)\n",
    "        C = extra_nodes - inputdata.dot(D)\n",
    "        BT = self.pinv(C) if (C == 0).any() else  np.mat((D.T.dot(D)+np.eye(D.shape[1]))).I.dot(D.T).dot(self.pesuedoinverse)\n",
    "        \n",
    "        self.W = np.row_stack((self.W-D.dot(BT).dot(label),BT.dot(label))) \n",
    "        self.pesuedoinverse =  np.row_stack((self.pesuedoinverse - D.dot(BT),BT)) \n",
    "        self.local_mapgeneratorlist.append(localmap_generator)\n",
    "        self.local_enhgeneratorlist.append(localenhence_generator)\n",
    "\n",
    "    \n",
    "    def adding_predict(self, data, label, mapstep = 1, enhencestep = 1, batchsize = 'auto'):\n",
    "         #对数据增量化\n",
    "        data = np.hstack([data, 0.1 * np.ones([data.shape[0],1])])\n",
    "        #print(data.shape)\n",
    "        self.adding_nodes(data, label, mapstep, enhencestep, batchsize)\n",
    "        test_inputdata = self.transform(data) \n",
    "        return test_inputdata.dot(self.W) \n",
    "    \n",
    "    def incremental_input(self, traindata, extratraindata, extratrainlabel):\n",
    "        data = np.hstack([traindata, 0.1 * np.ones([traindata.shape[0],1])])\n",
    "        data = self.transform(data)\n",
    "        \n",
    "        xdata = np.hstack([extratraindata, 0.1 * np.ones([extratraindata.shape[0],1])])\n",
    "        xdata = self.transform(xdata).T\n",
    "        xlabel = np.mat(extratrainlabel).T\n",
    "        DT = xdata.T.dot(self.pesuedoinverse)\n",
    "        #print(self.pesuedoinverse.shape)\n",
    "        CT = xdata.T - DT.dot(data)\n",
    "        B = self.pinv(CT) if (CT.T == 0).any() else self.pesuedoinverse.dot(DT.T).dot(np.mat((DT.dot(DT.T)+np.eye(DT.shape[0]))).I)\n",
    "    \n",
    "        self.W = self.W + B.dot((xlabel.T-xdata.T.dot(self.W)))\n",
    "        self.pesuedoinverse = np.column_stack((self.pesuedoinverse-B.dot(DT),B))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------加载数据集---------------#\n",
    "data = pd.read_csv(\"./data/test_data.csv\")\n",
    "df = pd.DataFrame(data)\n",
    "X  = np.double(df.iloc[:,2:])\n",
    "#print(traindata)\n",
    "Y = np.double(df.iloc[:,1:2])\n",
    "\n",
    "traindata1 = X[0:5000,:]\n",
    "trainlabel1 = Y[0:5000,:]\n",
    "testdata1 = X[5000:10000,:]\n",
    "testlabel1 = Y[5000:10000,:]\n",
    "\n",
    "traindata1,testdata1,trainlabel1,testlabel1 = train_test_split(X,Y,test_size=0.4)\n",
    "print(traindata1.shape, trainlabel1.shape, testdata1.shape, testlabel1.shape)\n",
    "#不断分割测试集，模拟新数据的输入\n",
    "traindata21,testdata21,trainlabel21,testlabel21 = train_test_split(testdata1,testlabel1,test_size=0.7,random_state = 2018)\n",
    "traindata22,testdata22,trainlabel22,testlabel22 = train_test_split(testdata21,testlabel21,test_size=0.7,random_state = 2018)\n",
    "traindata31,testdata31,trainlabel31,testlabel31 = train_test_split(testdata22,testlabel22,test_size=0.7,random_state = 2018)\n",
    "traindata32,testdata32,trainlabel32,testlabel32 = train_test_split(testdata31,testlabel31,test_size=0.7,random_state = 2018)\n",
    "\n",
    "bls = broadnet(NumWin = 10,    #映射节点数\n",
    "               NumEnhence = 500,   #增强节点数\n",
    "               traintimes = 5,    #训练迭代次数\n",
    "               map_function = 'tanh',   #映射方法\n",
    "               enhence_function = 'sigmoid',   #增强层激活函数\n",
    "               NumFea = 'auto',    #每批次样本数\n",
    "               acc = 1,\n",
    "               mapstep = 1,    #映射单元节点数\n",
    "               enhencestep = 1,   #\n",
    "               reg = 2**-30)\n",
    "\n",
    "bls.fit(traindata1,trainlabel1)\n",
    "predictlabel = bls.predict(testdata1)\n",
    "RMSE, MAPE, R2 = show_accuracy(predictlabel,testlabel1)\n",
    "print(\"RMSE:\",RMSE)\n",
    "print(\"MAPE:\",MAPE)\n",
    "print(\"R2:\",R2)\n",
    "bls.incremental_input(traindata1, traindata21, trainlabel21)\n",
    "predictlabel = bls.predict(testdata32)\n",
    "RMSE, MAPE, R2 = show_accuracy(predictlabel,testlabel32)\n",
    "print(\"RMSE:\",RMSE)\n",
    "print(\"MAPE:\",MAPE)\n",
    "print(\"R2:\",R2)\n",
    "\n",
    "bls.incremental_input(np.row_stack((traindata1,traindata21)), traindata22, trainlabel22)\n",
    "predictlabel = bls.predict(testdata32)\n",
    "print(show_accuracy(predictlabel,testlabel32))\n",
    "\n",
    "bls.incremental_input(np.row_stack((traindata1,traindata21,traindata22)), traindata31, trainlabel31)\n",
    "predictlabel = bls.predict(testdata32)\n",
    "print(show_accuracy(predictlabel,testlabel32))\n",
    "\n",
    "bls.incremental_input(np.row_stack((traindata1,traindata21,traindata22,traindata31)), traindata32, trainlabel32)\n",
    "predictlabel = bls.predict(testdata32)\n",
    "print(show_accuracy(predictlabel,testlabel32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
